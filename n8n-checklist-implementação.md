# ‚úÖ CHECKLIST & DIAGRAMA - IMPLEMENTA√á√ÉO PR√ÅTICA

**Documento T√©cnico v1.0** | Serinews Intelligence | Janeiro 2026

---

## üöÄ FASE 1: PR√â-IMPLEMENTA√á√ÉO (Semana 1)

### **1.1 Provisionar Infraestrutura**

- [ ] N8N instance (cloud.n8n.io OU self-hosted)
  - [ ] Conta criada
  - [ ] Admin user configurado
  - [ ] 2FA habilitado
  - [ ] Backup autom√°tico ativado
  
- [ ] Supabase project criado
  - [ ] Projeto criado em https://app.supabase.com
  - [ ] Database URL anotado
  - [ ] Service Key gerado
  - [ ] RLS policies configuradas
  
- [ ] Google Cloud Project (Gemini + YouTube)
  - [ ] Projeto criado
  - [ ] Billing habilitado
  - [ ] Gemini API ativada
  - [ ] YouTube Data API ativada
  - [ ] API keys geradas

### **1.2 Obter Credenciais**

| API | Onde Obter | Validade | A√ß√£o |
|-----|-----------|----------|------|
| **Gemini** | https://ai.google.dev/new | Indefinida | Gerar nova API key |
| **YouTube** | Google Cloud Console | Indefinida | Criar credentials |
| **Reddit** | https://www.reddit.com/prefs/apps | Indefinida | Create app (script) |
| **Lusha** | https://app.lusha.com/settings/api | 1 ano | Solicitar API key |
| **SharpSpring** | Help ‚Üí API Credentials | Indefinida | Anotar Account ID + Key |
| **RapidAPI** | https://rapidapi.com/profile/settings | 1 ano | Subscribe LinkedIn API |
| **Slack** | https://api.slack.com/apps | Indefinida | Create Bot Token |

### **1.3 Criar `.env.example`**

```bash
# Copiar para .env (NUNCA fazer commit deste arquivo)

# Google APIs
GEMINI_API_KEY=AIza...
YOUTUBE_API_KEY=AIza...

# Third-party APIs
REDDIT_CLIENT_ID=...
REDDIT_CLIENT_SECRET=...
REDDIT_USER_AGENT=RevistaED-Bot/1.0

LUSHA_API_KEY=...
RAPIDAPI_KEY=...

# SharpSpring
SHARPSPRING_ACCOUNT_ID=123456
SHARPSPRING_API_KEY=...
SHARPSPRING_SECRET_KEY=...

# Supabase
SUPABASE_URL=https://project.supabase.co
SUPABASE_KEY=eyJ...

# Slack
SLACK_BOT_TOKEN=xoxb-...
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...

# N8N
N8N_WEBHOOK_URL=https://seu-n8n.com/webhook/
N8N_EXECUTION_MODE=queue
```

---

## üóÑÔ∏è FASE 2: BANCO DE DADOS (Semana 1-2)

### **2.1 Executar Queries no Supabase**

**Abrir:** Supabase Dashboard ‚Üí SQL Editor ‚Üí Copiar/Colar cada query

#### **Query 1: Tabela de Not√≠cias Processadas**

```sql
-- Criar tabela para deduplica√ß√£o
CREATE TABLE IF NOT EXISTS noticia_processada (
  id BIGSERIAL PRIMARY KEY,
  content_hash VARCHAR(64) UNIQUE NOT NULL,
  original_title TEXT NOT NULL,
  original_url TEXT UNIQUE,
  source VARCHAR(50), -- 'reddit', 'youtube', 'linkedin', 'google_news'
  processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  execution_hour INTEGER CHECK (execution_hour IN (7, 11, 15, 19)),
  is_duplicate BOOLEAN DEFAULT FALSE,
  duplicate_of_id BIGINT REFERENCES noticia_processada(id),
  gemini_processing_ms INTEGER,
  c_levels_found INTEGER DEFAULT 0,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- √çndices para performance
CREATE INDEX idx_content_hash ON noticia_processada(content_hash);
CREATE INDEX idx_execution_hour ON noticia_processada(execution_hour);
CREATE INDEX idx_created_at ON noticia_processada(created_at DESC);
CREATE INDEX idx_is_duplicate ON noticia_processada(is_duplicate);

-- Enable RLS (Row Level Security)
ALTER TABLE noticia_processada ENABLE ROW LEVEL SECURITY;

-- Policy: Allow all (simples, pode ser restringido depois)
CREATE POLICY "Allow all operations" ON noticia_processada
FOR ALL USING (true);

-- Tabela de News Items (Conte√∫do do App) - Verifique se j√° existe
CREATE TABLE IF NOT EXISTS news_items (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  title TEXT NOT NULL,
  slug TEXT NOT NULL,
  excerpt TEXT NOT NULL,
  content TEXT,
  category TEXT NOT NULL,
  source TEXT NOT NULL,
  image_url TEXT,
  published_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  is_premium BOOLEAN DEFAULT FALSE,
  visibility TEXT DEFAULT 'public',
  key_points JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

#### **Query 2: Tabela de Execution Log**

```sql
CREATE TABLE IF NOT EXISTS execution_log (
  id BIGSERIAL PRIMARY KEY,
  execution_id VARCHAR(60) UNIQUE NOT NULL,
  execution_time TIMESTAMP NOT NULL,
  execution_hour INTEGER CHECK (execution_hour IN (7, 11, 15, 19)),
  status VARCHAR(20), -- 'success', 'partial', 'failed'
  noticia_processada JSONB,
  leads_found_count INTEGER DEFAULT 0,
  contact_created BOOLEAN DEFAULT FALSE,
  contact_updated BOOLEAN DEFAULT FALSE,
  email_sent BOOLEAN DEFAULT FALSE,
  errors JSONB, -- Array de erros
  processing_duration_ms INTEGER,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_execution_id ON execution_log(execution_id);
CREATE INDEX idx_execution_time ON execution_log(execution_time DESC);
CREATE INDEX idx_status ON execution_log(status);

ALTER TABLE execution_log ENABLE ROW LEVEL SECURITY;
CREATE POLICY "Allow all operations" ON execution_log FOR ALL USING (true);
```

#### **Query 3: Tabela de API Rate Limits**

```sql
CREATE TABLE IF NOT EXISTS api_rate_log (
  id BIGSERIAL PRIMARY KEY,
  api_name VARCHAR(50), -- 'gemini', 'lusha', 'sharpspring', etc.
  request_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  status_code INTEGER,
  response_time_ms INTEGER,
  error_message TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_api_name ON api_rate_log(api_name);
CREATE INDEX idx_request_time ON api_rate_log(request_time DESC);

ALTER TABLE api_rate_log ENABLE ROW LEVEL SECURITY;
CREATE POLICY "Allow all operations" ON api_rate_log FOR ALL USING (true);
```

#### **Query 4: Tabela de Email Consent (LGPD)**

```sql
CREATE TABLE IF NOT EXISTS email_consent (
  id BIGSERIAL PRIMARY KEY,
  email VARCHAR(255) UNIQUE NOT NULL,
  consent_given BOOLEAN DEFAULT FALSE,
  opted_out BOOLEAN DEFAULT FALSE,
  opted_out_at TIMESTAMP,
  consent_date TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_email ON email_consent(email);
CREATE INDEX idx_opted_out ON email_consent(opted_out);

ALTER TABLE email_consent ENABLE ROW LEVEL SECURITY;
CREATE POLICY "Allow all operations" ON email_consent FOR ALL USING (true);
```

#### **Query 5: View para KPIs**

```sql
CREATE OR REPLACE VIEW daily_kpis AS
SELECT 
  DATE(execution_time) as execution_date,
  COUNT(*) as total_executions,
  COUNT(CASE WHEN status='success' THEN 1 END) as successful_executions,
  COUNT(CASE WHEN status='failed' THEN 1 END) as failed_executions,
  SUM(leads_found_count) as total_leads_found,
  SUM(CASE WHEN contact_created THEN 1 END) as total_contacts_created,
  SUM(CASE WHEN contact_updated THEN 1 END) as total_contacts_updated,
  SUM(CASE WHEN email_sent THEN 1 END) as total_emails_sent,
  AVG(processing_duration_ms) as avg_processing_time_ms,
  MIN(processing_duration_ms) as min_processing_time_ms,
  MAX(processing_duration_ms) as max_processing_time_ms
FROM execution_log
GROUP BY DATE(execution_time)
ORDER BY execution_date DESC;
```

### **2.2 Verificar Credenciais no Supabase**

```bash
# Testar conex√£o
curl -X GET "https://[YOUR_SUPABASE_URL]/rest/v1/noticia_processada?limit=1" \
  -H "apikey: [YOUR_SUPABASE_KEY]" \
  -H "Authorization: Bearer [YOUR_SUPABASE_KEY]"

# Deve retornar: {"data": [], "count": null, "status": 200}
```

---

## üîß FASE 3: CONSTRUIR WORKFLOW N8N (Semana 2-3)

### **3.1 Estrutura do Workflow**

```
Workflow: "RevistaED - Curadoria Autom√°tica"
Tipo: Production
Modo: Trigger ‚Üí Execute

Nodes a criar:
‚îú‚îÄ 1. Schedule Trigger (07h, 11h, 15h, 19h)
‚îú‚îÄ 2. Reddit API Request
‚îú‚îÄ 3. YouTube API Request
‚îú‚îÄ 4. LinkedIn RapidAPI Request
‚îú‚îÄ 5. Google News RSS
‚îú‚îÄ 6. Merge Results
‚îú‚îÄ 7. Split Out
‚îú‚îÄ 8. Filter Political Content
‚îú‚îÄ 9. Generate Dedup Hash
‚îú‚îÄ 10. Check Supabase Dedup
‚îú‚îÄ 11. Conditional: Skip if Duplicate
‚îú‚îÄ 12. Wait (4s rate limit)
‚îú‚îÄ 13. Gemini Content Generation
‚îú‚îÄ 14. Extract C-Levels
‚îú‚îÄ 15. Split C-Levels
‚îú‚îÄ 16. Lusha Enrich
‚îú‚îÄ 17. Conditional: Valid Email?
‚îú‚îÄ 18. SharpSpring Check Contact
‚îú‚îÄ 19. Conditional: Contact Exists?
‚îú‚îÄ 20. SharpSpring Create/Update
‚îú‚îÄ 21. SharpSpring Send Email
‚îú‚îÄ 22. Prepare Log
‚îú‚îÄ 23. Save Log to Supabase
‚îî‚îÄ 24. Slack Notification
```

### **3.2 Criar Cada Node (Ordem de Prioridade)**

#### **PRIORIDADE 1: Core Nodes (Hoje)**

```
‚úì Node 1: Schedule Trigger
  - Settings ‚Üí Cron: 0 7,11,15,19 * * *
  - Timezone: America/Sao_Paulo

‚úì Node 2: HTTP Request (Reddit)
  - Method: GET
  - URL: https://api.reddit.com/r/startups/hot?limit=2
  - Headers: User-Agent: RevistaED-Bot/1.0
  - Return All Items: ON

‚úì Node 7: Split Out
  - Input Array: Merge Results (combinar os 4 sources)
  - Output: 1 item por not√≠cia

‚úì Node 10: HTTP Request (Supabase Check)
  - Autentica√ß√£o: Bearer token
  - Validar deduplica√ß√£o
```

#### **PRIORIDADE 2: Processing Nodes (Dia 2)**

```
‚úì Node 8: Code Node (Filter Political)
  - L√≥gica JavaScript fornecida no doc anterior
  
‚úì Node 9: Code Node (Generate Hash)
  - SHA-256 do t√≠tulo + URL
  
‚úì Node 13: HTTP Request (Gemini)
  - POST a generativelanguage.googleapis.com
  - Body com system prompt + conte√∫do
```

#### **PRIORIDADE 3: Integration Nodes (Dia 3)**

```
‚úì Node 16: HTTP Request (Lusha)
  - Query params: firstName, lastName, company
  - Tratamento: null se n√£o encontrado

‚úì Node 18: HTTP Request (SharpSpring Search)
  - Body: method=searchContacts, email
  
‚úì Node 20: HTTP Request (SharpSpring Create/Update)
  - Dois nodes paralelos com condicional
  
‚úì Node 21: HTTP Request (SharpSpring Email)
  - method=applyTemplate
```

#### **PRIORIDADE 4: Logging & Notifications (Dia 4)**

```
‚úì Node 22: Code Node (Prepare Log)
  - Estruturar dados para Supabase
  
‚úì Node 23: HTTP Request (Supabase INSERT)
  - POST a /rest/v1/execution_log
  
‚úì Node 24: Slack (native node)
  - Notifica√ß√£o com resumo
```

### **3.3 Testar Cada Node**

Para cada node criado:

```
1. Preencher configura√ß√µes (vide docs anteriores)
2. Clicar "Test step" ou "Execute workflow"
3. Validar sa√≠da:
   - Status code 200?
   - Dados no formato esperado?
   - Nenhum erro de autentica√ß√£o?
4. Se falhar: debugar com console.log (Code Nodes)
5. Se sucesso: marcar ‚úÖ e prosseguir
```

---

## üß™ FASE 4: TESTES & VALIDA√á√ÉO (Semana 3-4)

### **4.1 Teste Unit√°rio por Node**

```bash
# Teste 1: Schedule Trigger
[ ] Manual: Clicar "Execute workflow"
[ ] Verificar: Workflow iniciado nas 4 horas especificadas

# Teste 2: Reddit API
[ ] Mock: Testar com subreddit p√∫blico (r/news)
[ ] Verificar: JSON com posts recebido
[ ] Validar: Score, URL, cria√ß√£o do objeto normalizado

# Teste 3: Filtro Pol√≠tico
[ ] Input: { title: "Elei√ß√£o para presidente" }
[ ] Output: null ou skipped
[ ] Input: { title: "Startup levanta $5M" }
[ ] Output: Objeto processado

# Teste 4: Deduplica√ß√£o
[ ] Hash gerado corretamente? SHA-256(title + url)
[ ] Lookup em Supabase retorna corretamente?
[ ] Duplicata √© pulada? ‚úì

# Teste 5: Gemini
[ ] API key v√°lida?
[ ] Prompt formatado corretamente?
[ ] Resposta com 6 se√ß√µes esperadas?
[ ] C-levels extra√≠dos? (regex funcionando)

# Teste 6: Lusha
[ ] Encontra contato existente? (CEO conhecido)
[ ] Retorna null se n√£o encontrado?
[ ] Email √© v√°lido? (validar regex)

# Teste 7: SharpSpring
[ ] Autentica corretamente? (Account ID + API Key)
[ ] Cria contato novo?
[ ] Atualiza contato existente?
[ ] Dispara email?

# Teste 8: Logging
[ ] Logs salvos em Supabase?
[ ] Queries em execution_log?
[ ] Slack notification enviada?
```

### **4.2 Teste Integrado (End-to-End)**

```bash
# Cen√°rio 1: Not√≠cia nova, C-level encontrado
[ ] Execute workflow
[ ] Validar: Not√≠cia em noticia_processada
[ ] Validar: Artigo salvo em news_items (Supabase)
[ ] Validar: Contact criado em SharpSpring
[ ] Validar: Email enviado
[ ] Validar: Log em execution_log status=success

# Cen√°rio 2: Not√≠cia duplicada
[ ] Execute workflow 2x com mesma not√≠cia
[ ] Validar: 1¬™ execu√ß√£o: success
[ ] Validar: 2¬™ execu√ß√£o: skipped (is_duplicate=true)

# Cen√°rio 3: Nenhum C-level encontrado
[ ] Not√≠cia sobre tema geral (sem protagonistas)
[ ] Validar: c_levels_count=0
[ ] Validar: Email N√ÉO enviado
[ ] Validar: Log com warning "No protagonists found"

# Cen√°rio 4: Rate limit (Gemini)
[ ] Disparar 20 requests em < 1 minuto
[ ] Validar: Wait node faz backoff
[ ] Validar: Todos processados eventualmente
```

### **4.3 Teste de Carga**

```bash
# Simular 4 execu√ß√µes seguidas (como ocorreria em produ√ß√£o)

Execu√ß√£o 1 (07:00): 8 not√≠cias ‚Üí esperado 16-20 leads
Execu√ß√£o 2 (11:00): 8 not√≠cias ‚Üí esperado 16-20 leads (novas)
Execu√ß√£o 3 (15:00): 8 not√≠cias ‚Üí esperado 16-20 leads (novas)
Execu√ß√£o 4 (19:00): 8 not√≠cias ‚Üí esperado 16-20 leads (novas)

Total/dia: ~64-80 contatos criados/atualizados
Total/m√™s: ~1920-2400 leads qualificados

Verificar:
[ ] Nenhum timeout
[ ] Nenhuma falha de API
[ ] Logs completos
[ ] SharpSpring recebendo todos os dados
```

---

## üöÄ FASE 5: DEPLOY EM PRODU√á√ÉO (Semana 4)

### **5.1 Pr√©-Deployment Checklist**

- [ ] Todas as API keys em `.env` (n√£o em c√≥digo)
- [ ] Supabase RLS policies ativadas
- [ ] SharpSpring template criado e ID configurado
- [ ] Slack webhook configurado
- [ ] Logs de erro alertam para Slack
- [ ] Backup autom√°tico N8N ativado
- [ ] Rate limits testados
- [ ] 2FA N8N habilitado
- [ ] VCS: Workflow exportado como JSON (backup)
- [ ] Monitoramento: Dashboard Supabase criado

### **5.2 Deploy Steps**

```bash
# 1. Backup do workflow atual
Workflow ‚Üí Menu ‚Üí Export ‚Üí Salvar JSON em reposit√≥rio Git

# 2. Ativar Schedule Trigger
Node 1 (Schedule Trigger) ‚Üí Active: ON

# 3. Testar primeiro ciclo
Aguardar execu√ß√£o em 07:00 amanh√£
Verificar logs em Supabase
Validar notifica√ß√£o Slack

# 4. Monitorar por 7 dias
Executar diariamente
Sem interrup√ß√µes esperadas
```

### **5.3 P√≥s-Deployment Monitoring**

```bash
# Daily (autom√°tico via query Supabase)
- [ ] Todas 4 execu√ß√µes rodaram?
- [ ] Taxa de sucesso > 95%?
- [ ] M√©dia de dura√ß√£o normal (< 2 min)?
- [ ] Leads criados > 16 por execu√ß√£o?

# Weekly
- [ ] Total de leads gerados > 300?
- [ ] Erros agrupados por tipo?
- [ ] Taxa de enriquecimento Lusha > 70%?
- [ ] Duplica√ß√£o < 5%?

# Monthly
- [ ] Review de KPIs com stakeholders
- [ ] Otimiza√ß√µes baseadas em dados
- [ ] Atualiza√ß√£o de prompts Gemini se necess√°rio
```

---

## üìä FASE 6: OTIMIZA√á√ÉO CONT√çNUA

### **6.1 Ajustes Mensais**

| M√©trica | Target | Se Abaixo... | A√ß√£o |
|---------|--------|-------------|------|
| **Taxa de sucesso** | > 95% | Revisar logs de erro |
| **Leads gerados/dia** | > 32 | Aumentar limite de not√≠cias ou fontes |
| **Taxa de enriquecimento** | > 70% | Validar qualidade dados Lusha |
| **Taxa de abertura email** | > 30% | Testar novo subject/template |
| **Tempo processamento** | < 2 min | Otimizar rate limiting |

### **6.2 Escalabilidade Futura**

Quando atingir 5.000+ contatos/m√™s:

- [ ] Implementar caching de resultados Lusha
- [ ] Paralelizar Gemini requests (rate limit vs performance)
- [ ] Migrar Supabase para plano pagado
- [ ] Implementar webhooks N8N em vez de polling
- [ ] Adicionar mais fontes (Twitter/X, newsletters)

---

## üé® DIAGRAMA MERMAID - FLUXO COMPLETO

```mermaid
graph TD
    A["üïê Trigger Agendado<br/>07h, 11h, 15h, 19h"] --> B["üì° Coleta Paralela"]
    
    B --> B1["Reddit API"]
    B --> B2["YouTube API"]
    B --> B3["LinkedIn RapidAPI"]
    B --> B4["Google News RSS"]
    
    B1 --> C["üîÄ Merge & Normalize"]
    B2 --> C
    B3 --> C
    B4 --> C
    
    C --> D["üìã Split Out<br/>Uma linha por not√≠cia"]
    
    D --> E["üö´ Filter Political<br/>& Validar Niche"]
    
    E -->|Skip| F["‚ùå Log Rejection"]
    
    E -->|Pass| G["üîê Generate Hash<br/>SHA-256"]
    
    G --> H["üîç Check Supabase<br/>Dedup"]
    
    H -->|Duplicate| F
    H -->|New| I["‚è∏Ô∏è Wait 4s<br/>Rate Limit"]
    
    I --> J["ü§ñ Gemini API<br/>Content Generation"]
    
    J --> K["üéØ Extract C-Levels<br/>Regex + Parse"]
    
    K --> L["üë• Split C-Levels"]
    
    L --> M["üåê Lusha API<br/>Person Search"]
    
    M -->|No Email| F
    M -->|Found| N["‚úâÔ∏è SharpSpring<br/>Check Contact"]
    
    N -->|New| O["‚ûï Create Contact"]
    N -->|Exists| P["‚úèÔ∏è Update Contact"]
    
    O --> Q["üìß Send Email<br/>Campaign"]
    P --> Q
    
    Q --> R["üìù Prepare Log"]
    R --> S["üíæ Save Supabase"]
    R --> T["üí¨ Slack Notify"]
    
    S --> U["‚úÖ Execution Complete"]
    T --> U
    
    F --> V["‚ùå Log to Supabase"]
    V --> U
    
    style A fill:#4285F4,stroke:#1a73e8,color:#fff
    style J fill:#FF9800,stroke:#E65100,color:#fff
    style M fill:#4CAF50,stroke:#2E7D32,color:#fff
    style Q fill:#9C27B0,stroke:#6A1B9A,color:#fff
    style U fill:#4285F4,stroke:#1a73e8,color:#fff
```

---

## üì± TEMPLATE: DAILY STANDUP REPORT

**Copiar para Slack a cada dia √†s 08:00**

```
üìä *RevistaED Automa√ß√£o - Daily Report* 
Data: {{ today }}

‚úÖ *Execu√ß√£o 07h*
Not√≠cias processadas: 8
Leads encontrados: 18
Emails disparados: 18
Erros: 0

‚úÖ *Execu√ß√£o 11h* (pendente)
Not√≠cias processadas: -
Leads encontrados: -
Emails disparados: -
Erros: -

üìà *KPI Di√°rio At√© Agora*
- Taxa de sucesso: 100%
- Leads gerados: 18
- Contatos criados: 16
- Contatos atualizados: 2

‚ö†Ô∏è *Alertas (se houver)*
- Nenhum

*Pr√≥xima execu√ß√£o:* 11:00
```

---

## üéØ CONCLUS√ÉO

Ap√≥s completar as 6 fases:

‚úÖ Sistema totalmente operacional
‚úÖ 32+ leads qualificados/dia
‚úÖ Automa√ß√£o 100% integrada com SharpSpring
‚úÖ Monitoramento em tempo real
‚úÖ Pronto para escalar

**Pr√≥xima reuni√£o:** Semana 5 para avaliar resultados e planejar otimiza√ß√µes.
